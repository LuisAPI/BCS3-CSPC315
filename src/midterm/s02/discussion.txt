[Mathematical Tools for Analysis]

- asymptotic notation
    - it is used to describe the running time of an algo
        - how much time an algo takes with a given input n.
            - big O notation
                - worst running time
            - big Theta Notation
            - big Omega notation
                - best running time
        - runtimes
            - it is based on the slowest part of the program
                O(2N) + O(log N) + O(1)
                - O(2N) -> O(N)
- O Notation
    - combining time complexity

//Function with O(n) time complexity
void linearfunction(int n){
    for(int i = 0; i < n; i++)
        cout << "O(n) operations."
    }
}

//Function with O(n^2) time complexity
void quadraticFunction(int n){
    for(int i = 0; i < n; i++){
        for(int j = 0; j < n; j++){
            cout << "O(n^2) operations."
        }
    
    }
}

//Combined function demonstration O(n) + O(n^2) = O(n^3) -> f1(n) + f2(n) = O(g1(n)) . O(g2(n))
void combinedFunction(int n){
    linearFunction(n) //O(n)
    quadraticFunction(n) //O(n^2)
}

int main(){
    int n = 3; //test with n = 3
    combinedFunction;
    return 0;
}

Theorem: If f1(n) = O(g1(n)) and k â‰  0 is a constant, then kf(n) = O(kg(n)) = O(g(n)).
    - this theory says that multiplying a function by a constant does not change its big O notation
        - complexity of algo, constant does not matter because big O focuses on the growth rate as the input size n becomes large
    - algo O(n^2)




[example]







//Function that scales the time complexity by constant kf
void scaleFunction(int n, int k){
    for(int i = 0; i < k; i++){
        //executes linear function k times
        linearFunction(n);
        }

    }
}

int main(){
    int n = 5;
    //constant multiplier
    int k = 3;
    //O(n), calls linearFunction k time, even though it performs the operation k time because k is constant
    scaleFunction(n, k);
    return 0;
}
















        - algo takes the same amount of time, no matter the size of the input

        - ex:
        int arr[] = {1, 2, 3, 4, 5}
        count << "Access element at index 2: " << arr [2] >> endl;
    
    - linear O(n)
        - the time taken grows directly in proportion to the input size

        - ex:
        int linearSearch(int arr[], int n, int x){
            // loop 0 to n-1 to examine each element in the array
            // this for loop runs n time
            for (int i = 0; i < n; i++){      --> O(n)
                //constant time comparison O(1)
                if(arr[i] == x)               --> O(1)
                    //best case: O(1) if found at the beginning
                    return i
            }
            //worst case: O(n) if element is not found  --> O(n) = O(n)
            return -1;
        } //O(n)


    - quadratic(polynomial) O(n^2)
        - the time taken grows by the square (or higher powers)of the input size often seen with nested loops

        - ex:
        voit bubbleSort(int arr[], int n){
            for(int i = 0; i < n-1; i++){           O(n) . O(n) -- O(n^2)
                for(int j = 0; j <= n-i; j++){      O(n)     - O(n)
                    if(arr[j] > arr[j + 1])         O(n)    - O(n)
                        swap(arr[j], arr[j + 1])    O(1)
                }
            }
        }

    - logarithmic           O(log n)
        - the runtime increases logarithmically, usually seen in algo that halve the input size in each step

        - ex:
        int binarySearch(int arr[], int r, int x){

            while (l <= r) {
                int mid = l + (r - l) / 2; (n/2)(n/4) --> log2(n) = O(log n)
                if (arr[mid] == x)
                    return mid; //O(1)
                else if (arr[mid] < x)
                    l = mid + 1; //O(1)
                else
                    r = mid - 1; O(1)
            }
            return -1;
        }
    - exponential           O(2^n)
        - the time taken doubles with each additional input often seen in algo that solve subproblem multiple times

        - ex:
        int fibonacci(int n){
            //base case: if n is 0 or 1, return n O(1)
            if(n <= 1)
                return n;
            //recursive: (n-1), (n-2) -- (n-1), (n-2), (n-3)
            return fibonacci(n-1) + fibonacci(n-2); //O(n) + O(n) --> O(2^n)

        }

                        fibonacci(5)
                        /           \
                    fibonacci(4)    fibonacci(3)
                    /         \      /              \
            fibonacci(3)fibonacci(2)fibonacci(2)    fibonacci(1)
        /                   \             /         \
    fibonacci(2)        fibonacci(1)   fibonacci(1) fibonacci(1)
    /           \
fibonacci(1)    fibonacci(0)

    - factorial             O(n!)
        - the time taken grows as the factorial of input size often seen in algo that computes all possible permutation of a set

        void permute(string str, int l, int r) {
            if (l == r)
                cout << str << endl; //O(1)
            else {
                for (int i = l; i <= r; i++) { //O(n)
                    swap(str[l], str[i]); //O(1)
                    permute(str, l + 1, r); O(n!)

                    swap(str[l], str[i]); // Backtrack
                }
            }
        }